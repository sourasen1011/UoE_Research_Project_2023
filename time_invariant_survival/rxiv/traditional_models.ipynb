{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n"
     ]
    }
   ],
   "source": [
    "from general_utils import *\n",
    "\n",
    "# Traditional\n",
    "from lifelines import CoxPHFitter\n",
    "from lifelines import WeibullAFTFitter\n",
    "\n",
    "# Tree-Based\n",
    "from sksurv.ensemble import RandomSurvivalForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get configs\n",
    "with open(config_file_path, \"r\") as file:\n",
    "    configs = json.load(file)\n",
    "# Get configs\n",
    "with open(config_file_path, \"r\") as file:\n",
    "    configs = json.load(file)\n",
    "\n",
    "# Read the pickled DataFrames\n",
    "with open('../05_preprocessing_emr_data/data/x_train.pickle', 'rb') as file:\n",
    "    x_train = pickle.load(file)\n",
    "with open('../05_preprocessing_emr_data/data/x_test.pickle', 'rb') as file:\n",
    "    x_test = pickle.load(file)\n",
    "with open('../05_preprocessing_emr_data/data/x_val.pickle', 'rb') as file:\n",
    "    x_val = pickle.load(file)\n",
    "\n",
    "# Read the pickled DataFrame\n",
    "with open('../05_preprocessing_emr_data/data/consolidated_pat_tbl.pickle', 'rb') as file:\n",
    "    consolidated_pat_tbl = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _traditional_fitter:\n",
    "    '''\n",
    "    simple wrapper class for cox proportional hazards\n",
    "    '''\n",
    "    def __init__(self , configs , train_data , test_data , val_data):\n",
    "        self.train_data = train_data\n",
    "        self.test_data = test_data\n",
    "        self.val_data = val_data\n",
    "        self.configs = configs\n",
    "        # state var\n",
    "        self.fitted = False\n",
    "        self.fitter = None\n",
    "\n",
    "    def eval(self , fitter_is_rsf = False):\n",
    "        if not self.fitted:\n",
    "            raise Exception('Model not fitted yet!')\n",
    "            \n",
    "        # get evaluation - with a tweak for RSF. not the best. but works for now.\n",
    "        if not fitter_is_rsf:\n",
    "            # predict\n",
    "            _surv = self.fitter.predict_survival_function(self.test_data.iloc[: , :-2])\n",
    "            ev = EvalSurv(pd.DataFrame(_surv), self.test_data['time_to_event'].to_numpy(), self.test_data['death'].to_numpy(), censor_surv='km')\n",
    "        else:\n",
    "            # predict\n",
    "            _surv = self.fitter.predict_survival_function(self.test_data.iloc[: , :-2] , return_array = True)\n",
    "            ev = EvalSurv(pd.DataFrame(_surv.T), self.test_data['time_to_event'].to_numpy(), self.test_data['death'].to_numpy(), censor_surv='km')\n",
    "        \n",
    "        # get time grid\n",
    "        time_grid_div = self.configs['time_invariant']['eval']['time_grid_div']\n",
    "        time_grid = np.linspace(self.test_data['time_to_event'].min(), self.test_data['time_to_event'].max(), time_grid_div)\n",
    "        # get metrics\n",
    "        cindex = ev.concordance_td('antolini')\n",
    "        ibs = ev.integrated_brier_score(time_grid)\n",
    "        return cindex , ibs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CPH(_traditional_fitter):\n",
    "    def __init__(self , configs , train_data , test_data , val_data):\n",
    "        super(CPH , self).__init__(configs , train_data , test_data , val_data)\n",
    "\n",
    "    def fit(self):\n",
    "        # init CPH\n",
    "        cph = CoxPHFitter(penalizer = 0.1)\n",
    "        # fit\n",
    "        cph.fit(self.train_data, duration_col='time_to_event', event_col='death', fit_options = {'step_size':0.1})\n",
    "        # assign the fitted model to a class attr\n",
    "        self.fitter = cph\n",
    "        # change state var\n",
    "        self.fitted = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AFT(_traditional_fitter):\n",
    "    def __init__(self , configs , train_data , test_data , val_data):\n",
    "        super(AFT , self).__init__(configs , train_data , test_data , val_data)\n",
    "\n",
    "    def fit(self):\n",
    "        # init AFT\n",
    "        aft = WeibullAFTFitter(penalizer = 0.01)\n",
    "        eps = 1e-8\n",
    "        self.train_data['time_to_event'] = self.train_data['time_to_event'] + eps\n",
    "        # fit\n",
    "        aft.fit(self.train_data, duration_col='time_to_event', event_col='death')\n",
    "\n",
    "        # assign the fitted model to a class attr\n",
    "        self.fitter = aft\n",
    "        # change state var\n",
    "        self.fitted = True   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RSF(_traditional_fitter):\n",
    "    def __init__(self , configs , train_data , test_data , val_data):\n",
    "        super(RSF , self).__init__(configs , train_data , test_data , val_data)\n",
    "\n",
    "    def fit(self):\n",
    "        # Train - Create a structured array\n",
    "        y_train = np.array([(x, y) for x, y in zip(self.train_data['death'].astype('bool') , self.train_data['time_to_event'])],\n",
    "                                    dtype=[('death', bool) , ('time_to_event', int)])\n",
    "\n",
    "        # init RSF\n",
    "        rsf = RandomSurvivalForest(\n",
    "            n_estimators=100, min_samples_split=10, min_samples_leaf=15, n_jobs=-1, oob_score = True\n",
    "        )\n",
    "        rsf.fit(self.train_data.iloc[: , :-2], y_train)\n",
    "\n",
    "        # assign the fitted model to a class attr\n",
    "        self.fitter = rsf\n",
    "        # change state var\n",
    "        self.fitted = True   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shapes : (1060, 1060, 1060, 1060)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6953971238645091, 0.17313085627507496)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cph = CPH(configs = configs, train_data = x_train, test_data = x_test, val_data = x_val)\n",
    "\n",
    "# fit\n",
    "cph.fit()\n",
    "# eval\n",
    "cph.eval(fitter_is_rsf = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shapes : (1060, 1060, 1060, 1060)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6953838819884001, 0.17419123792832816)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aft = AFT(configs = configs, train_data = x_train, test_data = x_test, val_data = x_val)\n",
    "\n",
    "# fit\n",
    "aft.fit()\n",
    "# eval\n",
    "aft.eval(fitter_is_rsf = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shapes : (1060, 1060, 1060, 1060)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6906300484652665, 0.20274623694935368)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rsf = RSF(configs = configs, train_data = x_train, test_data = x_test, val_data = x_val)\n",
    "\n",
    "# fit\n",
    "rsf.fit()\n",
    "# eval\n",
    "rsf.eval(fitter_is_rsf = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # PyCox\n",
    "# from pycox.datasets import metabric\n",
    "# from pycox.models import LogisticHazard\n",
    "# import torchtuples as tt\n",
    "\n",
    "# # Deep Survival Machines\n",
    "# from auton_survival.models.dsm import DeepSurvivalMachines"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
