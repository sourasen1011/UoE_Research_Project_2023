{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n"
     ]
    }
   ],
   "source": [
    "from general_utils import *\n",
    "from model_utils import *\n",
    "from losses import *\n",
    "from models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the pickled DataFrames\n",
    "with open('../05_preprocessing_emr_data/data/x_train_reshape_tv.pickle', 'rb') as file:\n",
    "    x_train_reshape_tv = pickle.load(file)\n",
    "with open('../05_preprocessing_emr_data/data/x_test_reshape_tv.pickle', 'rb') as file:\n",
    "    x_test_reshape_tv = pickle.load(file)\n",
    "with open('../05_preprocessing_emr_data/data/x_val_reshape_tv.pickle', 'rb') as file:\n",
    "    x_val_reshape_tv = pickle.load(file)\n",
    "\n",
    "# Read the pickled targets\n",
    "with open('../05_preprocessing_emr_data/data/y_train.pickle', 'rb') as file:\n",
    "    y_train = pickle.load(file)\n",
    "with open('../05_preprocessing_emr_data/data/y_test.pickle', 'rb') as file:\n",
    "    y_test = pickle.load(file)\n",
    "with open('../05_preprocessing_emr_data/data/y_val.pickle', 'rb') as file:\n",
    "    y_val = pickle.load(file)\n",
    "\n",
    "# Get configs\n",
    "with open(config_file_path, \"r\") as file:\n",
    "    configs = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Time_Variant_Survival:\n",
    "    '''\n",
    "    Class for fitting, testing, evaluating and explaining survival distributions\n",
    "    '''\n",
    "    def __init__(self, configs, x_train_reshape_tv, x_test_reshape_tv, x_val_reshape_tv, y_train, y_test, y_val):\n",
    "        '''\n",
    "        configs - dictionary created from loaded json file that contains all configs parsed from config file\n",
    "        train_data - self.explanatory\n",
    "        test_data - self.explanatory\n",
    "        val_data - self.explanatory\n",
    "        '''\n",
    "        self.configs = configs\n",
    "        # load patient images\n",
    "        self.x_train_reshape_tv = x_train_reshape_tv\n",
    "        self.x_test_reshape_tv = x_test_reshape_tv\n",
    "        self.x_val_reshape_tv = x_val_reshape_tv\n",
    "        # test\n",
    "        assert self.x_train_reshape_tv.dim() == self.x_test_reshape_tv.dim() == self.x_val_reshape_tv.dim() == 4 , 'dimensions not correct'\n",
    "\n",
    "        # load targets\n",
    "        self.y_train = y_train\n",
    "        self.y_test = y_test\n",
    "        self.y_val = y_val\n",
    "\n",
    "        # state vars\n",
    "        self.fitted = False\n",
    "        self.predicted = False\n",
    "        \n",
    "        # read from config file\n",
    "        self.q_cuts = self.configs['time_invariant']['training']['q_cuts']    # number of discretized durations\n",
    "        self.hidden_size = self.configs['time_invariant']['training']['hidden_size'] # hidden size of MLP\n",
    "        self.output_size = self.q_cuts # same as discretizations\n",
    "        self.alpha = self.configs['time_invariant']['training']['alpha'] # trade off between two loss functions\n",
    "        self.batch_size = self.configs['time_invariant']['training']['batch_size'] # batch size for NN\n",
    "        self.num_epochs = self.configs['time_invariant']['training']['num_epochs'] # Number of epochs for NN\n",
    "        self.learning_rate = self.configs['time_invariant']['training']['learning_rate'] # LR for NN\n",
    "        self.shuffle = self.configs['time_invariant']['training']['shuffle'] # shuffle for Dataloader class\n",
    "        self.patience = self.configs['time_invariant']['training']['patience'] # patience for early stopping\n",
    "        self.dropout = self.configs['time_invariant']['training']['dropout'] # dropout for training and MC dropout  \n",
    "\n",
    "    def fit(self , verbose = False):\n",
    "        '''\n",
    "        fitter function\n",
    "        verbose: print on or off\n",
    "        '''\n",
    "        input_size = 7 * self.x_train_reshape_tv.shape[2] * self.x_train_reshape_tv.shape[3]\n",
    "        \n",
    "        # init loss\n",
    "        l = generic_Loss()\n",
    "\n",
    "        # init besst loss for early stopping\n",
    "        best_loss = np.Inf\n",
    "\n",
    "        # get features\n",
    "        features = self.x_train_reshape_tv\n",
    "\n",
    "        # get death time and event indicator\n",
    "        y_train_dur , y_train_event = get_target(self.y_train)\n",
    "\n",
    "        t_train = Transforms(durations = y_train_dur)\n",
    "        dur_idx = t_train.discrete_transform(_cuts = self.q_cuts)\n",
    "            \n",
    "        # Create an instance of your custom dataset\n",
    "        dataset = MyDataset(features, dur_idx , y_train_dur , y_train_event) # need to change outcomes[0] to indexed version\n",
    "        dataloader = DataLoader(dataset, batch_size = self.batch_size, shuffle = self.shuffle)    \n",
    "\n",
    "        # build net\n",
    "        self.net = Net(input_size , self.hidden_size , self.output_size , self.dropout)\n",
    "        # init optim\n",
    "        optimizer = torch.optim.Adam(self.net.parameters() , lr = self.learning_rate)\n",
    "        \n",
    "        # Prepare validation data\n",
    "        # get duration, event\n",
    "        y_val_dur , y_val_event = get_target(self.y_val)\n",
    "        \n",
    "        # transform to discrete\n",
    "        t_val = Transforms(durations = y_val_dur)\n",
    "        dur_idx_val = t_val.discrete_transform(_cuts = self.q_cuts)\n",
    "                        \n",
    "        # build surv matrix for val data\n",
    "        sm_val = Surv_Matrix(duration_index = dur_idx_val , events = y_val_event , q_cuts = self.q_cuts)\n",
    "        surv_mat_val = sm_val.make_survival_matrix()\n",
    "\n",
    "        # Training loop\n",
    "        for epoch in range(self.num_epochs):\n",
    "            for batch_id , (patient_image , dur_idx , dur , eve) in enumerate(dataloader):\n",
    "                # Prime for training\n",
    "                self.net.train()\n",
    "                    \n",
    "                # forward pass\n",
    "                phi_train = self.net(patient_image)\n",
    "\n",
    "                # make survival matrix\n",
    "                sm = Surv_Matrix(duration_index = dur_idx, events = eve , q_cuts = self.q_cuts)\n",
    "                surv_mat = sm.make_survival_matrix()           \n",
    "\n",
    "                # get loss\n",
    "                loss_1 = l.nll_logistic_hazard(\n",
    "                    logits = phi_train , \n",
    "                    targets = surv_mat , \n",
    "                    dur_idx = dur_idx\n",
    "                    )\n",
    "                loss_2 = l.c_index_lbo_loss(\n",
    "                    logits = phi_train , \n",
    "                    times = dur , \n",
    "                    events = eve\n",
    "                    )\n",
    "                \n",
    "                # combine\n",
    "                loss = self.alpha*loss_1 + (1-self.alpha)*(loss_2)\n",
    "\n",
    "                # backward pass\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                    \n",
    "                # Early stopping\n",
    "                with torch.no_grad():\n",
    "                    # compute loss\n",
    "                    phi_val = self.net(self.x_val_reshape_tv) # do we need to add torch.Tensor? might be redundant. \n",
    "                    val_loss_1 = l.nll_logistic_hazard(\n",
    "                        logits = phi_val, \n",
    "                        targets = surv_mat_val , \n",
    "                        dur_idx = dur_idx_val\n",
    "                        )\n",
    "                    val_loss_2 = l.c_index_lbo_loss(\n",
    "                        logits = phi_val , \n",
    "                        times = torch.Tensor(y_val_dur) , \n",
    "                        events = torch.Tensor(y_val_event)\n",
    "                        )\n",
    "\n",
    "                    # combine\n",
    "                    val_loss = self.alpha*val_loss_1 + (1-self.alpha)*(val_loss_2)\n",
    "                    \n",
    "                # Check if validation loss has improved\n",
    "                if val_loss < best_loss:\n",
    "                    best_loss = val_loss\n",
    "                    counter = 0\n",
    "                else:\n",
    "                    counter += 1\n",
    "\n",
    "                # Check if early stopping condition is met\n",
    "                if counter >= self.patience:\n",
    "                    # print(f\"Early stopping at epoch {epoch}.\")\n",
    "                    break\n",
    "                \n",
    "            # control verbosity\n",
    "            if verbose:\n",
    "                if ((epoch+1)%50==0): \n",
    "                    print(f\"Epoch {epoch+1}: Training Loss: {loss.item():.7f}, Val Loss: {val_loss.item():.7f}\") \n",
    "        \n",
    "        # change state\n",
    "        self.fitted = True\n",
    "\n",
    "    def predict(self):\n",
    "        '''\n",
    "        this is the prediction suite\n",
    "        '''       \n",
    "        if not self.fitted:\n",
    "            raise Exception(\"Model isn't fitted yet!\")\n",
    "\n",
    "        # Testing\n",
    "        surv = [] # length will be equal to number of cluster\n",
    "        mc_iter = self.configs['time_invariant']['testing']['mc_iter']\n",
    "        conf_int_lower = self.configs['time_invariant']['testing']['conf_int_lower']\n",
    "        conf_int_upper = self.configs['time_invariant']['testing']['conf_int_upper']\n",
    "        \n",
    "        # get features, death time and event indicator\n",
    "        features = self.x_test_reshape_tv # do we need to add torch.Tensor? might be redundant. \n",
    "            \n",
    "        # get death time and event indicator\n",
    "        y_test_dur , y_test_event = get_target(self.y_test)\n",
    "\n",
    "        surv = []\n",
    "\n",
    "        # apply Monte Carlo dropout\n",
    "        for _ in range(mc_iter):\n",
    "                \n",
    "            # Prime dropout layers\n",
    "            self.net.train()\n",
    "                \n",
    "            # predict\n",
    "            mc_haz = torch.sigmoid(self.net(features))\n",
    "            mc_survival = torch.cumprod(1 - mc_haz , dim = 1).detach().numpy()\n",
    "\n",
    "            # append survivals from different runs\n",
    "            surv.append(mc_survival)\n",
    "            \n",
    "        # convert to 3d array\n",
    "        surv = np.array(surv)\n",
    "\n",
    "        # get stats\n",
    "        mean_ = np.mean(surv , axis = 0)\n",
    "        up_ = np.quantile(surv , axis = 0 , q = conf_int_upper)\n",
    "        low_ = np.quantile(surv , axis = 0 , q = conf_int_lower)\n",
    "\n",
    "        # QCs\n",
    "        assert mean_.shape[0] == up_.shape[0] == low_.shape[0] == y_test_dur.shape[0] == y_test_event.shape[0] , 'shape mismatch'\n",
    "\n",
    "        # change\n",
    "        self.predicted = True\n",
    "        \n",
    "        return mean_ , up_ , low_ , y_test_dur , y_test_event\n",
    "\n",
    "    \n",
    "    def visualize(self , mean_ , low_ , up_ , _from , _to):\n",
    "        '''\n",
    "        visualize the predictions\n",
    "        '''\n",
    "        # get features, death time and event indicator\n",
    "        features = self.test_data\n",
    "\n",
    "        # get death time and event indicator\n",
    "        y_test_dur_ , y_test_event_ = get_target(features)\n",
    "\n",
    "        t_test = Transforms(durations = y_test_dur_)\n",
    "        dur_idx_test = t_test.discrete_transform(_cuts = self.q_cuts) # although we don't use the dur_idx_test variable,\n",
    "        # we actually need the fitted t_test object\n",
    "\n",
    "        # get transparency for graph\n",
    "        transparency = self.configs['time_invariant']['test_viz']['transparency']\n",
    "        _ = plot_with_cf(t_test.bin_edges, mean_ , low_ , up_ , _from , _to , transparency = transparency)\n",
    "\n",
    "\n",
    "    def evaluation(self , mean_ , y_test_dur , y_test_event , plot = False):\n",
    "        '''\n",
    "        Evaluation by\n",
    "        1. td c-index\n",
    "        2. Brier score\n",
    "        3. IBS\n",
    "        '''\n",
    "        time_grid_div = self.configs['time_invariant']['eval']['time_grid_div']\n",
    "        time_grid = np.linspace(y_test_dur.min(), y_test_dur.max(), time_grid_div)\n",
    "        \n",
    "        # Evaluation\n",
    "        ev_ = EvalSurv(pd.DataFrame(mean_.T) , y_test_dur , y_test_event , censor_surv='km')\n",
    "        \n",
    "        # brier score\n",
    "        if plot:\n",
    "            ev_.brier_score(time_grid).plot()\n",
    "            plt.ylabel('Brier score')\n",
    "            _ = plt.xlabel('Time')\n",
    "\n",
    "        # td c-index\n",
    "        tdci = ev_.concordance_td()\n",
    "        # print(f'concordance-td: {tdci}')\n",
    "        \n",
    "        # IBS\n",
    "        ibs = ev_.integrated_brier_score(time_grid)\n",
    "        # print(f'integrated brier score {ibs}')\n",
    "        \n",
    "        return tdci , ibs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50: Training Loss: -0.0044511, Val Loss: 0.0012752\n",
      "Epoch 100: Training Loss: -0.0071080, Val Loss: -0.0017846\n",
      "Epoch 150: Training Loss: -0.0041394, Val Loss: -0.0018320\n",
      "Epoch 200: Training Loss: -0.0050649, Val Loss: -0.0018948\n",
      "Epoch 250: Training Loss: -0.0027902, Val Loss: 0.0003127\n",
      "Epoch 300: Training Loss: -0.0037919, Val Loss: 0.0006441\n",
      "Epoch 350: Training Loss: -0.0045497, Val Loss: 0.0011992\n",
      "Epoch 400: Training Loss: -0.0054573, Val Loss: 0.0011567\n",
      "shapes : (1180, 1180, 1180, 1180)\n"
     ]
    }
   ],
   "source": [
    "# instantiate - Time variant Survival\n",
    "tvs = Time_Variant_Survival(\n",
    "        configs = configs, \n",
    "        x_train_reshape_tv = x_train_reshape_tv,\n",
    "        x_test_reshape_tv = x_test_reshape_tv, \n",
    "        x_val_reshape_tv = x_val_reshape_tv,\n",
    "        y_train = y_train,\n",
    "        y_test = y_test,\n",
    "        y_val = y_val\n",
    "    )\n",
    "\n",
    "# fit\n",
    "tvs.fit(verbose = True)\n",
    "mean_ , up_ , low_ , y_test_dur , y_test_event = tvs.predict() # Visualize -> tis.visualize(mean_ , up_ , low_ , _from = 40 , _to = 50 )\n",
    "tvs_cindex , tvs_ibs = tvs.evaluation(mean_ , y_test_dur , y_test_event, plot = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7327243913991824, 0.40199505949039926)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tvs_cindex , tvs_ibs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
