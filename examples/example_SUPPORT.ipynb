{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "sys.path.append('../nn_survival_analysis')\n",
    "from nn_survival_analysis.general_utils import *\n",
    "from nn_survival_analysis.model_utils import *\n",
    "from nn_survival_analysis.losses import *\n",
    "from nn_survival_analysis.models import *\n",
    "from nn_survival_analysis.other_nn_models import *\n",
    "from nn_survival_analysis.time_invariant_surv import *\n",
    "from nn_survival_analysis.time_variant_surv import *\n",
    "from nn_survival_analysis.traditional_models import *\n",
    "import scipy\n",
    "from pycox.datasets import support\n",
    "from sklearn_pandas import DataFrameMapper\n",
    "from pycox.preprocessing.feature_transforms import OrderedCategoricalLong\n",
    "\n",
    "# define sigmoid function - will be handy later\n",
    "sigmoid = lambda z : 1 / (1 + np.exp(-z))\n",
    "\n",
    "config_file_path = '../nn_survival_analysis/config.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get configs\n",
    "with open('../nn_survival_analysis/config.json', \"r\") as file:\n",
    "    configs = json.load(file)\n",
    "\n",
    "df_train = support.read_df()\n",
    "df_test = df_train.sample(frac=0.2)\n",
    "df_train = df_train.drop(df_test.index)\n",
    "df_val = df_train.sample(frac=0.2)\n",
    "df_train = df_train.drop(df_val.index)\n",
    "\n",
    "cols_standardize =  ['x0', 'x7', 'x8', 'x9', 'x10', 'x11', 'x12', 'x13']\n",
    "cols_leave = ['x1', 'x4', 'x5']\n",
    "cols_categorical =  ['x2', 'x3', 'x6']\n",
    "\n",
    "standardize = [([col], StandardScaler()) for col in cols_standardize]\n",
    "leave = [(col, None) for col in cols_leave]\n",
    "categorical = [(col, OrderedCategoricalLong()) for col in cols_categorical]\n",
    "\n",
    "x_mapper = DataFrameMapper(standardize + leave + categorical)\n",
    "\n",
    "x_train = x_mapper.fit_transform(df_train).astype('float32')\n",
    "x_val = x_mapper.transform(df_val).astype('float32')\n",
    "x_test = x_mapper.transform(df_test).astype('float32')\n",
    "\n",
    "get_target = lambda df: (df['duration'].values, df['event'].values)\n",
    "y_train_dur , y_train_event = get_target(df_train)\n",
    "y_test_dur , y_test_event = get_target(df_test)\n",
    "y_val_dur , y_val_event = get_target(df_val)\n",
    "\n",
    "_df_train = np.concatenate([x_train , y_train_dur.reshape(-1 , 1) , y_train_event.reshape(-1 , 1)] , axis = 1)\n",
    "_df_test = np.concatenate([x_test , y_test_dur.reshape(-1 , 1) , y_test_event.reshape(-1 , 1)] , axis = 1)\n",
    "_df_val = np.concatenate([x_val , y_val_dur.reshape(-1 , 1) , y_val_event.reshape(-1 , 1)] , axis = 1)\n",
    "\n",
    "_df_train = pd.DataFrame(_df_train , columns = df_train.columns)\n",
    "_df_test = pd.DataFrame(_df_test , columns = df_test.columns)\n",
    "_df_val = pd.DataFrame(_df_val , columns = df_val.columns)\n",
    "\n",
    "_df_train.rename(columns = {'duration':'time_to_event' , 'event':'death'} , inplace = True)\n",
    "_df_test.rename(columns = {'duration':'time_to_event' , 'event':'death'} , inplace = True)\n",
    "_df_val.rename(columns = {'duration':'time_to_event' , 'event':'death'} , inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training cluster 0\n",
      "Epoch 50: Training Loss: 0.0020189, Val Loss: -0.0074056\n",
      "Epoch 100: Training Loss: -0.0140832, Val Loss: -0.0080518\n",
      "Epoch 150: Training Loss: -0.0136744, Val Loss: -0.0078765\n",
      "Epoch 200: Training Loss: -0.0150570, Val Loss: -0.0120581\n",
      "Epoch 250: Training Loss: -0.0139139, Val Loss: -0.0091328\n",
      "Epoch 300: Training Loss: -0.0033458, Val Loss: -0.0154889\n",
      "Epoch 350: Training Loss: -0.0062397, Val Loss: -0.0097667\n",
      "Epoch 400: Training Loss: 0.0045828, Val Loss: -0.0111534\n",
      "Epoch 450: Training Loss: -0.0209305, Val Loss: -0.0097705\n",
      "Epoch 500: Training Loss: -0.0274025, Val Loss: -0.0131506\n",
      "Epoch 550: Training Loss: -0.0050691, Val Loss: -0.0100244\n",
      "Epoch 600: Training Loss: -0.0206057, Val Loss: -0.0102631\n",
      "shapes : (1775, 1775, 1775, 1775)\n",
      "0.5909738587770982 0.22665645619362926\n",
      "CPU times: total: 4min 24s\n",
      "Wall time: 1min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#-----------------------------------------------------------------------------------------------\n",
    "# instantiate - Time Invariant Survival\n",
    "tis = Time_Invariant_Survival(\n",
    "        configs = configs, \n",
    "        train_data = _df_train,\n",
    "        test_data = _df_test, \n",
    "        val_data = _df_val\n",
    ")\n",
    "\n",
    "# fit\n",
    "tis.fit(verbose = True)\n",
    "mean_ , up_ , low_ , y_test_dur , y_test_event = tis.predict() # Visualize -> tis.visualize(mean_ , up_ , low_ , _from = 40 , _to = 50 )\n",
    "tis_cindex , tis_ibs = tis.evaluation(mean_ , y_test_dur , y_test_event, plot = False)\n",
    "print(tis_cindex , tis_ibs)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Other Fitters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\t[0s / 0s],\t\ttrain_loss: 2.4025,\tval_loss: 2.0611\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 2.0385,\tval_loss: 1.7303\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 1.6756,\tval_loss: 1.4173\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 1.3905,\tval_loss: 1.2589\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 1.2738,\tval_loss: 1.2196\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 1.2288,\tval_loss: 1.2049\n",
      "6:\t[0s / 0s],\t\ttrain_loss: 1.2128,\tval_loss: 1.1995\n",
      "7:\t[0s / 0s],\t\ttrain_loss: 1.1993,\tval_loss: 1.1954\n",
      "8:\t[0s / 1s],\t\ttrain_loss: 1.1851,\tval_loss: 1.1895\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 1.1788,\tval_loss: 1.1902\n",
      "10:\t[0s / 1s],\t\ttrain_loss: 1.1708,\tval_loss: 1.1882\n",
      "11:\t[0s / 1s],\t\ttrain_loss: 1.1779,\tval_loss: 1.1852\n",
      "12:\t[0s / 1s],\t\ttrain_loss: 1.1544,\tval_loss: 1.1854\n",
      "13:\t[0s / 1s],\t\ttrain_loss: 1.1602,\tval_loss: 1.1857\n",
      "14:\t[0s / 1s],\t\ttrain_loss: 1.1702,\tval_loss: 1.1853\n",
      "15:\t[0s / 1s],\t\ttrain_loss: 1.1506,\tval_loss: 1.1816\n",
      "16:\t[0s / 1s],\t\ttrain_loss: 1.1550,\tval_loss: 1.1879\n",
      "17:\t[0s / 1s],\t\ttrain_loss: 1.1548,\tval_loss: 1.1849\n",
      "18:\t[0s / 2s],\t\ttrain_loss: 1.1519,\tval_loss: 1.1836\n",
      "19:\t[0s / 2s],\t\ttrain_loss: 1.1368,\tval_loss: 1.1809\n",
      "20:\t[0s / 2s],\t\ttrain_loss: 1.1451,\tval_loss: 1.1800\n",
      "21:\t[0s / 2s],\t\ttrain_loss: 1.1364,\tval_loss: 1.1824\n",
      "22:\t[0s / 2s],\t\ttrain_loss: 1.1321,\tval_loss: 1.1821\n",
      "23:\t[0s / 2s],\t\ttrain_loss: 1.1411,\tval_loss: 1.1857\n",
      "24:\t[0s / 2s],\t\ttrain_loss: 1.1475,\tval_loss: 1.1853\n",
      "25:\t[0s / 2s],\t\ttrain_loss: 1.1417,\tval_loss: 1.1807\n",
      "26:\t[0s / 2s],\t\ttrain_loss: 1.1476,\tval_loss: 1.1836\n",
      "27:\t[0s / 3s],\t\ttrain_loss: 1.1399,\tval_loss: 1.1819\n",
      "28:\t[0s / 3s],\t\ttrain_loss: 1.1399,\tval_loss: 1.1817\n",
      "29:\t[0s / 3s],\t\ttrain_loss: 1.1334,\tval_loss: 1.1822\n",
      "30:\t[0s / 3s],\t\ttrain_loss: 1.1364,\tval_loss: 1.1844\n",
      "shapes : (1775, 1775, 1775, 1775)\n",
      "PyCox: cindex 0.49924457084110396 , ibs 0.21461938706746952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 1173/10000 [00:01<00:11, 760.11it/s]\n",
      " 51%|█████     | 51/100 [00:05<00:05,  8.54it/s]\n",
      " 12%|█▏        | 1173/10000 [00:01<00:11, 770.12it/s]\n",
      " 14%|█▍        | 14/100 [00:02<00:12,  6.80it/s]\n",
      " 12%|█▏        | 1173/10000 [00:01<00:11, 758.15it/s]\n",
      " 46%|████▌     | 46/100 [00:06<00:07,  7.63it/s]\n",
      " 12%|█▏        | 1173/10000 [00:01<00:11, 758.18it/s]\n",
      " 14%|█▍        | 14/100 [00:02<00:13,  6.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shapes : (1775, 1775, 1775, 1775)\n",
      "Deep Survival Machines: cindex 0.5864674406684972 , ibs 0.24281393212331515\n",
      "shapes : (1775, 1775, 1775, 1775)\n",
      "Cox Proportional Hazards: cindex 0.5765378804391086 , ibs 0.209033969777541\n",
      "shapes : (1775, 1775, 1775, 1775)\n",
      "Weibull Accelerated Failure Time: cindex 0.5755321293580378 , ibs 0.21012863114671942\n",
      "shapes : (1775, 1775, 1775, 1775)\n",
      "Random Survival Forest: cindex 0.6277225763593447 , ibs 0.19519703490214144\n",
      "CPU times: total: 4min 38s\n",
      "Wall time: 2min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#-----------------------------------------------------------------------------------------------\n",
    "# instantiate - PyCox\n",
    "pyc = PYC(configs = configs, train_data = _df_train, test_data = _df_test, val_data = _df_val, num_durations = 10)\n",
    "\n",
    "# fit\n",
    "pyc.fit()\n",
    "\n",
    "# eval\n",
    "pyc_cindex , pyc_ibs = pyc.eval()\n",
    "        \n",
    "print(f'PyCox: cindex {pyc_cindex} , ibs {pyc_ibs}')\n",
    "#-----------------------------------------------------------------------------------------------\n",
    "# instantiate - Deep Survival Machines\n",
    "dsm = DSM(configs = configs, train_data = _df_train, test_data = _df_test, val_data = _df_val, num_durations = 10)\n",
    "\n",
    "# fit\n",
    "dsm.fit()\n",
    "\n",
    "# eval\n",
    "dsm_cindex , dsm_ibs = dsm.eval()\n",
    "       \n",
    "print(f'Deep Survival Machines: cindex {dsm_cindex} , ibs {dsm_ibs}')\n",
    "\n",
    "# -----------------------------------------------------------------------------------------------\n",
    "# instantiate - CPH\n",
    "cph = CPH(configs = configs, train_data = _df_train, test_data = _df_test, val_data = _df_val)\n",
    "\n",
    "# fit\n",
    "cph.fit()\n",
    "# eval\n",
    "cph_cindex , cph_ibs = cph.eval(fitter_is_rsf = False)\n",
    "        \n",
    "print(f'Cox Proportional Hazards: cindex {cph_cindex} , ibs {cph_ibs}')\n",
    "\n",
    "#-----------------------------------------------------------------------------------------------\n",
    "# instantiate - AFT\n",
    "aft = AFT(configs = configs, train_data = _df_train, test_data = _df_test, val_data = _df_val)\n",
    "\n",
    "# fit\n",
    "aft.fit()\n",
    "# eval\n",
    "aft_cindex , aft_ibs = aft.eval(fitter_is_rsf = False)\n",
    "        \n",
    "print(f'Weibull Accelerated Failure Time: cindex {aft_cindex} , ibs {aft_ibs}')\n",
    "\n",
    "#-----------------------------------------------------------------------------------------------\n",
    "# instantiate - RSF\n",
    "rsf = RSF(configs = configs, train_data = _df_train, test_data = _df_test, val_data = _df_val)\n",
    "\n",
    "# fit\n",
    "rsf.fit()\n",
    "# eval\n",
    "rsf_cindex , rsf_ibs = rsf.eval(fitter_is_rsf = True)\n",
    "\n",
    "\n",
    "print(f'Random Survival Forest: cindex {rsf_cindex} , ibs {rsf_ibs}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
