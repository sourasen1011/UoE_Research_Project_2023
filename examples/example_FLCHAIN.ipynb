{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "sys.path.append('../nn_survival_analysis')\n",
    "from nn_survival_analysis.general_utils import *\n",
    "from nn_survival_analysis.model_utils import *\n",
    "from nn_survival_analysis.losses import *\n",
    "from nn_survival_analysis.models import *\n",
    "from nn_survival_analysis.other_nn_models import *\n",
    "from nn_survival_analysis.time_invariant_surv import *\n",
    "from nn_survival_analysis.time_variant_surv import *\n",
    "from nn_survival_analysis.traditional_models import *\n",
    "import scipy\n",
    "\n",
    "# define sigmoid function - will be handy later\n",
    "sigmoid = lambda z : 1 / (1 + np.exp(-z))\n",
    "\n",
    "config_file_path = '../nn_survival_analysis/config.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "flchain = pd.read_csv(\"../resources/other_data/FLCHAIN.csv\")\n",
    "flchain.rename(columns = {'futime':'time_to_event'} , inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_splitter(df , test_size = 0.2 , val_size = 0.25 , duration_col = 'futime' , event_col = 'death'):\n",
    "    df_test = df.sample(frac=test_size)\n",
    "    df_train = df.drop(df_test.index)\n",
    "\n",
    "    df_val = df_train.sample(frac=val_size)\n",
    "    df_train = df_train.drop(df_val.index)\n",
    "\n",
    "    return df_train , df_val , df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoded_sex_data.shape (7874, 1)\n",
      "encoded_chap_data.shape (7874, 1)\n",
      "flchain_mod.shape (7874, 11)\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of the OneHotEncoder class\n",
    "encoder1 = LabelEncoder()\n",
    "encoder2 = LabelEncoder()\n",
    "\n",
    "# Fit and transform the data\n",
    "encoded_sex_data = encoder1.fit_transform(flchain['sex'])\n",
    "encoded_sex_data = pd.DataFrame(encoded_sex_data.reshape(-1 , 1) , columns = ['sex']) \n",
    "print(f'encoded_sex_data.shape {encoded_sex_data.shape}')\n",
    "\n",
    "# Fit and transform the data\n",
    "encoded_chap_data = encoder2.fit_transform(flchain['chapter'])\n",
    "encoded_chap_data = pd.DataFrame(encoded_chap_data.reshape(-1 , 1) , columns = ['chapter'])\n",
    "print(f'encoded_chap_data.shape {encoded_chap_data.shape}')\n",
    "\n",
    "flchain_mod = pd.DataFrame(\n",
    "    pd.concat(\n",
    "        [\n",
    "            encoded_sex_data , \n",
    "            encoded_chap_data , \n",
    "            flchain[['age' , 'sample.yr' , 'kappa' , 'lambda' , 'flc.grp' , 'creatinine' , 'mgus']] , \n",
    "            flchain[['time_to_event' , 'death']]\n",
    "        ] ,\n",
    "        axis = 1\n",
    "        )\n",
    "    )\n",
    "\n",
    "print(f'flchain_mod.shape {flchain_mod.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute(df):\n",
    "    _imputer = SimpleImputer(strategy='mean')\n",
    "    df_imp = pd.DataFrame(_imputer.fit_transform(df) , columns = df.columns)\n",
    "    return df_imp\n",
    "\n",
    "def scale(df):\n",
    "    _scaler = StandardScaler()\n",
    "    scale_cols = ['age' , 'sample.yr' , 'kappa' , 'lambda' , 'flc.grp' , 'creatinine' , 'mgus']\n",
    "    unscaled_cols = [col for col in df.columns if col not in scale_cols]\n",
    "    scaled = pd.DataFrame(_scaler.fit_transform(df[scale_cols]) , columns = scale_cols)\n",
    "    return pd.concat([scaled , df[unscaled_cols]] , axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train , df_test , df_val = train_test_splitter(flchain_mod)\n",
    "preprocess = lambda df: scale(impute(df))\n",
    "# preprocess train\n",
    "x_train = preprocess(df_train)\n",
    "\n",
    "# preprocess test\n",
    "x_test = preprocess(df_test)\n",
    "\n",
    "# preprocess val\n",
    "x_val = preprocess(df_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training cluster 0\n",
      "Epoch 50: Training Loss: -0.2409167, Val Loss: -0.2741865\n",
      "Epoch 100: Training Loss: -0.2657355, Val Loss: -0.3048589\n",
      "Epoch 150: Training Loss: -0.2934957, Val Loss: -0.3156575\n",
      "Epoch 200: Training Loss: -0.3343136, Val Loss: -0.3268056\n",
      "Epoch 250: Training Loss: -0.3424828, Val Loss: -0.3402769\n",
      "Epoch 300: Training Loss: -0.3323167, Val Loss: -0.3330546\n",
      "Epoch 350: Training Loss: -0.3458107, Val Loss: -0.3494644\n",
      "Epoch 400: Training Loss: -0.3638918, Val Loss: -0.3583965\n",
      "shapes : (1575, 1575, 1575, 1575)\n",
      "0.9245094591214367 0.10560674525871205\n",
      "CPU times: total: 13min 40s\n",
      "Wall time: 2min 40s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Get configs\n",
    "with open(config_file_path, \"r\") as file:\n",
    "        configs = json.load(file)\n",
    "\n",
    "#-----------------------------------------------------------------------------------------------\n",
    "# instantiate - Time Invariant Survival\n",
    "tis = Time_Invariant_Survival(\n",
    "        configs = configs, \n",
    "        train_data = x_train,\n",
    "        test_data = x_test, \n",
    "        val_data = x_val\n",
    ")\n",
    "\n",
    "# fit\n",
    "tis.fit(verbose = True)\n",
    "mean_ , up_ , low_ , y_test_dur , y_test_event = tis.predict() # Visualize -> tis.visualize(mean_ , up_ , low_ , _from = 40 , _to = 50 )\n",
    "tis_cindex , tis_ibs = tis.evaluation(mean_ , y_test_dur , y_test_event, plot = False)\n",
    "print(tis_cindex , tis_ibs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Other Fitters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\t[0s / 0s],\t\ttrain_loss: 4.3521,\tval_loss: 2.9553\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 3.4812,\tval_loss: 2.6144\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 2.6314,\tval_loss: 1.8869\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 1.7667,\tval_loss: 1.1986\n",
      "4:\t[0s / 1s],\t\ttrain_loss: 1.2120,\tval_loss: 0.8345\n",
      "5:\t[0s / 1s],\t\ttrain_loss: 0.9533,\tval_loss: 0.7522\n",
      "6:\t[0s / 1s],\t\ttrain_loss: 0.8554,\tval_loss: 0.6804\n",
      "7:\t[0s / 1s],\t\ttrain_loss: 0.8221,\tval_loss: 0.7595\n",
      "8:\t[0s / 2s],\t\ttrain_loss: 0.8317,\tval_loss: 0.7555\n",
      "9:\t[0s / 2s],\t\ttrain_loss: 0.7980,\tval_loss: 0.6709\n",
      "10:\t[0s / 2s],\t\ttrain_loss: 0.7718,\tval_loss: 0.6405\n",
      "11:\t[0s / 2s],\t\ttrain_loss: 0.7617,\tval_loss: 0.6620\n",
      "12:\t[0s / 2s],\t\ttrain_loss: 0.7467,\tval_loss: 0.6597\n",
      "13:\t[0s / 3s],\t\ttrain_loss: 0.7391,\tval_loss: 0.6364\n",
      "14:\t[0s / 3s],\t\ttrain_loss: 0.7096,\tval_loss: 0.6433\n",
      "15:\t[0s / 3s],\t\ttrain_loss: 0.7111,\tval_loss: 0.6191\n",
      "16:\t[0s / 3s],\t\ttrain_loss: 0.6867,\tval_loss: 0.6163\n",
      "17:\t[0s / 3s],\t\ttrain_loss: 0.6918,\tval_loss: 0.6395\n",
      "18:\t[0s / 4s],\t\ttrain_loss: 0.6962,\tval_loss: 0.6100\n",
      "19:\t[0s / 4s],\t\ttrain_loss: 0.6764,\tval_loss: 0.6374\n",
      "20:\t[0s / 4s],\t\ttrain_loss: 0.6781,\tval_loss: 0.6141\n",
      "21:\t[0s / 4s],\t\ttrain_loss: 0.6659,\tval_loss: 0.6115\n",
      "22:\t[0s / 5s],\t\ttrain_loss: 0.6739,\tval_loss: 0.6211\n",
      "23:\t[0s / 5s],\t\ttrain_loss: 0.6458,\tval_loss: 0.6052\n",
      "24:\t[0s / 5s],\t\ttrain_loss: 0.6589,\tval_loss: 0.5996\n",
      "25:\t[0s / 5s],\t\ttrain_loss: 0.6481,\tval_loss: 0.5995\n",
      "26:\t[0s / 5s],\t\ttrain_loss: 0.6539,\tval_loss: 0.6054\n",
      "27:\t[0s / 6s],\t\ttrain_loss: 0.6372,\tval_loss: 0.5965\n",
      "28:\t[0s / 6s],\t\ttrain_loss: 0.6218,\tval_loss: 0.6075\n",
      "29:\t[0s / 6s],\t\ttrain_loss: 0.6362,\tval_loss: 0.6018\n",
      "30:\t[0s / 6s],\t\ttrain_loss: 0.6271,\tval_loss: 0.5877\n",
      "31:\t[0s / 7s],\t\ttrain_loss: 0.6180,\tval_loss: 0.5904\n",
      "32:\t[0s / 7s],\t\ttrain_loss: 0.6218,\tval_loss: 0.5914\n",
      "33:\t[0s / 7s],\t\ttrain_loss: 0.6165,\tval_loss: 0.6074\n",
      "34:\t[0s / 7s],\t\ttrain_loss: 0.6071,\tval_loss: 0.5970\n",
      "35:\t[0s / 7s],\t\ttrain_loss: 0.6135,\tval_loss: 0.5907\n",
      "36:\t[0s / 8s],\t\ttrain_loss: 0.6092,\tval_loss: 0.5866\n",
      "37:\t[0s / 8s],\t\ttrain_loss: 0.6094,\tval_loss: 0.5952\n",
      "38:\t[0s / 8s],\t\ttrain_loss: 0.6102,\tval_loss: 0.5947\n",
      "39:\t[0s / 8s],\t\ttrain_loss: 0.6109,\tval_loss: 0.5883\n",
      "40:\t[0s / 9s],\t\ttrain_loss: 0.5939,\tval_loss: 0.5857\n",
      "41:\t[0s / 9s],\t\ttrain_loss: 0.6022,\tval_loss: 0.5995\n",
      "42:\t[0s / 9s],\t\ttrain_loss: 0.6048,\tval_loss: 0.5936\n",
      "43:\t[0s / 9s],\t\ttrain_loss: 0.6020,\tval_loss: 0.5985\n",
      "44:\t[0s / 10s],\t\ttrain_loss: 0.5975,\tval_loss: 0.5843\n",
      "45:\t[0s / 10s],\t\ttrain_loss: 0.5902,\tval_loss: 0.5905\n",
      "46:\t[0s / 10s],\t\ttrain_loss: 0.5917,\tval_loss: 0.5898\n",
      "47:\t[0s / 10s],\t\ttrain_loss: 0.5945,\tval_loss: 0.5860\n",
      "48:\t[0s / 10s],\t\ttrain_loss: 0.5936,\tval_loss: 0.5842\n",
      "49:\t[0s / 11s],\t\ttrain_loss: 0.5901,\tval_loss: 0.5824\n",
      "50:\t[0s / 11s],\t\ttrain_loss: 0.5972,\tval_loss: 0.5833\n",
      "51:\t[0s / 11s],\t\ttrain_loss: 0.5963,\tval_loss: 0.5795\n",
      "52:\t[0s / 11s],\t\ttrain_loss: 0.5818,\tval_loss: 0.5852\n",
      "53:\t[0s / 12s],\t\ttrain_loss: 0.5848,\tval_loss: 0.5882\n",
      "54:\t[0s / 12s],\t\ttrain_loss: 0.5766,\tval_loss: 0.5915\n",
      "55:\t[0s / 12s],\t\ttrain_loss: 0.5796,\tval_loss: 0.5789\n",
      "56:\t[0s / 12s],\t\ttrain_loss: 0.5750,\tval_loss: 0.5834\n",
      "57:\t[0s / 13s],\t\ttrain_loss: 0.5812,\tval_loss: 0.5870\n",
      "58:\t[0s / 13s],\t\ttrain_loss: 0.5793,\tval_loss: 0.5836\n",
      "59:\t[0s / 13s],\t\ttrain_loss: 0.5748,\tval_loss: 0.5826\n",
      "60:\t[0s / 13s],\t\ttrain_loss: 0.5768,\tval_loss: 0.5944\n",
      "61:\t[0s / 13s],\t\ttrain_loss: 0.5715,\tval_loss: 0.5825\n",
      "62:\t[0s / 14s],\t\ttrain_loss: 0.5777,\tval_loss: 0.5789\n",
      "63:\t[0s / 14s],\t\ttrain_loss: 0.5754,\tval_loss: 0.5874\n",
      "64:\t[0s / 14s],\t\ttrain_loss: 0.5744,\tval_loss: 0.5876\n",
      "65:\t[0s / 14s],\t\ttrain_loss: 0.5648,\tval_loss: 0.5810\n",
      "66:\t[0s / 15s],\t\ttrain_loss: 0.5713,\tval_loss: 0.5851\n",
      "67:\t[0s / 15s],\t\ttrain_loss: 0.5724,\tval_loss: 0.5866\n",
      "68:\t[0s / 15s],\t\ttrain_loss: 0.5612,\tval_loss: 0.5876\n",
      "69:\t[0s / 15s],\t\ttrain_loss: 0.5711,\tval_loss: 0.5869\n",
      "70:\t[0s / 16s],\t\ttrain_loss: 0.5649,\tval_loss: 0.5803\n",
      "71:\t[0s / 16s],\t\ttrain_loss: 0.5693,\tval_loss: 0.5828\n",
      "72:\t[0s / 16s],\t\ttrain_loss: 0.5676,\tval_loss: 0.5834\n",
      "shapes : (1575, 1575, 1575, 1575)\n",
      "PyCox: cindex 0.8981622557041552 , ibs 0.045890746058264376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:47<00:00, 211.76it/s]\n",
      "100%|██████████| 100/100 [00:30<00:00,  3.31it/s]\n",
      "100%|██████████| 10000/10000 [00:18<00:00, 540.38it/s]\n",
      "100%|██████████| 100/100 [00:16<00:00,  6.15it/s]\n",
      "100%|██████████| 10000/10000 [00:20<00:00, 492.70it/s]\n",
      "100%|██████████| 100/100 [00:18<00:00,  5.40it/s]\n",
      "100%|██████████| 10000/10000 [00:19<00:00, 517.61it/s]\n",
      "100%|██████████| 100/100 [00:17<00:00,  5.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shapes : (1575, 1575, 1575, 1575)\n",
      "Deep Survival Machines: cindex 0.0 , ibs nan\n",
      "shapes : (1575, 1575, 1575, 1575)\n",
      "Cox Proportional Hazards: cindex 0.8963734176024679 , ibs 0.07483696698342991\n",
      "shapes : (1575, 1575, 1575, 1575)\n",
      "Weibull Accelerated Failure Time: cindex 0.8930647254669601 , ibs 0.07575229651062905\n",
      "shapes : (1575, 1575, 1575, 1575)\n",
      "Random Survival Forest: cindex 0.9335308391174313 , ibs 0.07106165489894868\n",
      "CPU times: total: 22min 15s\n",
      "Wall time: 6min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#-----------------------------------------------------------------------------------------------\n",
    "# instantiate - PyCox\n",
    "pyc = PYC(configs = configs, train_data = x_train, test_data = x_test, val_data = x_val, num_durations = 10)\n",
    "\n",
    "# fit\n",
    "pyc.fit()\n",
    "\n",
    "# eval\n",
    "pyc_cindex , pyc_ibs = pyc.eval()\n",
    "        \n",
    "print(f'PyCox: cindex {pyc_cindex} , ibs {pyc_ibs}')\n",
    "#-----------------------------------------------------------------------------------------------\n",
    "# instantiate - Deep Survival Machines\n",
    "dsm = DSM(configs = configs, train_data = x_train, test_data = x_test, val_data = x_val, num_durations = 10)\n",
    "\n",
    "# fit\n",
    "dsm.fit()\n",
    "\n",
    "# eval\n",
    "dsm_cindex , dsm_ibs = dsm.eval()\n",
    "       \n",
    "print(f'Deep Survival Machines: cindex {dsm_cindex} , ibs {dsm_ibs}')\n",
    "\n",
    "# -----------------------------------------------------------------------------------------------\n",
    "# instantiate - CPH\n",
    "cph = CPH(configs = configs, train_data = x_train, test_data = x_test, val_data = x_val)\n",
    "\n",
    "# fit\n",
    "cph.fit()\n",
    "# eval\n",
    "cph_cindex , cph_ibs = cph.eval(fitter_is_rsf = False)\n",
    "        \n",
    "print(f'Cox Proportional Hazards: cindex {cph_cindex} , ibs {cph_ibs}')\n",
    "\n",
    "#-----------------------------------------------------------------------------------------------\n",
    "# instantiate - AFT\n",
    "aft = AFT(configs = configs, train_data = x_train, test_data = x_test, val_data = x_val)\n",
    "\n",
    "# fit\n",
    "aft.fit()\n",
    "# eval\n",
    "aft_cindex , aft_ibs = aft.eval(fitter_is_rsf = False)\n",
    "        \n",
    "print(f'Weibull Accelerated Failure Time: cindex {aft_cindex} , ibs {aft_ibs}')\n",
    "\n",
    "#-----------------------------------------------------------------------------------------------\n",
    "# instantiate - RSF\n",
    "rsf = RSF(configs = configs, train_data = x_train, test_data = x_test, val_data = x_val)\n",
    "\n",
    "# fit\n",
    "rsf.fit()\n",
    "# eval\n",
    "rsf_cindex , rsf_ibs = rsf.eval(fitter_is_rsf = True)\n",
    "\n",
    "\n",
    "print(f'Random Survival Forest: cindex {rsf_cindex} , ibs {rsf_ibs}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
