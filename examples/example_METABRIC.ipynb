{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "sys.path.append('../nn_survival_analysis')\n",
    "from nn_survival_analysis.general_utils import *\n",
    "from nn_survival_analysis.model_utils import *\n",
    "from nn_survival_analysis.losses import *\n",
    "from nn_survival_analysis.models import *\n",
    "from nn_survival_analysis.other_nn_models import *\n",
    "from nn_survival_analysis.time_invariant_surv import *\n",
    "from nn_survival_analysis.time_variant_surv import *\n",
    "from nn_survival_analysis.traditional_models import *\n",
    "import scipy\n",
    "from pycox.datasets import metabric\n",
    "from sklearn_pandas import DataFrameMapper \n",
    "\n",
    "# define sigmoid function - will be handy later\n",
    "sigmoid = lambda z : 1 / (1 + np.exp(-z))\n",
    "\n",
    "config_file_path = '../nn_survival_analysis/config.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_splitter(df , test_size = 0.2 , val_size = 0.25 , duration_col = 'futime' , event_col = 'death'):\n",
    "    df_test = df.sample(frac=test_size)\n",
    "    df_train = df.drop(df_test.index)\n",
    "\n",
    "    df_val = df_train.sample(frac=val_size)\n",
    "    df_train = df_train.drop(df_val.index)\n",
    "\n",
    "    return df_train , df_val , df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = metabric.read_df()\n",
    "df_train , df_test , df_val = train_test_splitter(df)\n",
    "\n",
    "cols_standardize = ['x0', 'x1', 'x2', 'x3', 'x8']\n",
    "cols_leave = ['x4', 'x5', 'x6', 'x7']\n",
    "\n",
    "standardize = [([col], StandardScaler()) for col in cols_standardize]\n",
    "leave = [(col, None) for col in cols_leave]\n",
    "\n",
    "x_mapper = DataFrameMapper(standardize + leave)\n",
    "\n",
    "x_train = x_mapper.fit_transform(df_train).astype('float32')\n",
    "x_val = x_mapper.transform(df_val).astype('float32')\n",
    "x_test = x_mapper.transform(df_test).astype('float32')\n",
    "\n",
    "get_target = lambda df: (df['duration'].values, df['event'].values)\n",
    "y_train_dur , y_train_event = get_target(df_train)\n",
    "y_test_dur , y_test_event = get_target(df_test)\n",
    "y_val_dur , y_val_event = get_target(df_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pd.DataFrame(x_mapper.fit_transform(df_train).astype('float32') , columns = df_train.iloc[: , :-2].columns)\n",
    "x_val = pd.DataFrame(x_mapper.transform(df_val).astype('float32') , columns = df_val.iloc[: , :-2].columns)\n",
    "x_test = pd.DataFrame(x_mapper.transform(df_test).astype('float32') , columns = df_test.iloc[: , :-2].columns)\n",
    "\n",
    "x_train = pd.concat([x_train , df_train[['duration' , 'event']].reset_index().drop('index' , axis = 1)] , axis = 1)\n",
    "x_test = pd.concat([x_test , df_test[['duration' , 'event']].reset_index().drop('index' , axis = 1)] , axis = 1)\n",
    "x_val = pd.concat([x_val , df_val[['duration' , 'event']].reset_index().drop('index' , axis = 1)] , axis = 1)\n",
    "\n",
    "x_train.rename(columns = {'duration':'time_to_event' , 'event': 'death'}, inplace = True)\n",
    "x_test.rename(columns = {'duration':'time_to_event' , 'event': 'death'}, inplace = True)\n",
    "x_val.rename(columns = {'duration':'time_to_event' , 'event': 'death'}, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training cluster 0\n",
      "Epoch 50: Training Loss: -0.0100063, Val Loss: -0.0123921\n",
      "Epoch 100: Training Loss: -0.0147883, Val Loss: -0.0147190\n",
      "Epoch 150: Training Loss: -0.0233001, Val Loss: -0.0218463\n",
      "Epoch 200: Training Loss: -0.0243625, Val Loss: -0.0233700\n",
      "Epoch 250: Training Loss: -0.0190197, Val Loss: -0.0248876\n",
      "Epoch 300: Training Loss: -0.0085105, Val Loss: -0.0208942\n",
      "Epoch 350: Training Loss: -0.0101741, Val Loss: -0.0218758\n",
      "Epoch 400: Training Loss: -0.0064592, Val Loss: -0.0239173\n",
      "Epoch 450: Training Loss: -0.0107445, Val Loss: -0.0200270\n",
      "Epoch 500: Training Loss: -0.0230233, Val Loss: -0.0128368\n",
      "Epoch 550: Training Loss: -0.0192515, Val Loss: -0.0248307\n",
      "Epoch 600: Training Loss: -0.0164496, Val Loss: -0.0216110\n",
      "shapes : (381, 381, 381, 381)\n",
      "0.5890650135363126 0.3872190798043313\n",
      "CPU times: total: 48.1 s\n",
      "Wall time: 9.37 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Get configs\n",
    "with open(config_file_path, \"r\") as file:\n",
    "        configs = json.load(file)\n",
    "        \n",
    "#-----------------------------------------------------------------------------------------------\n",
    "# instantiate - Time Invariant Survival\n",
    "tis = Time_Invariant_Survival(\n",
    "        configs = configs, \n",
    "        train_data = x_train,\n",
    "        test_data = x_test, \n",
    "        val_data = x_val\n",
    ")\n",
    "\n",
    "# fit\n",
    "tis.fit(verbose = True)\n",
    "mean_ , up_ , low_ , y_test_dur , y_test_event = tis.predict() # Visualize -> tis.visualize(mean_ , up_ , low_ , _from = 40 , _to = 50 )\n",
    "tis_cindex , tis_ibs = tis.evaluation(mean_ , y_test_dur , y_test_event, plot = False)\n",
    "print(tis_cindex , tis_ibs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Other Fitters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\t[0s / 0s],\t\ttrain_loss: 3.2039,\tval_loss: 2.8919\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 2.9687,\tval_loss: 2.8036\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 2.8297,\tval_loss: 2.6876\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 2.7513,\tval_loss: 2.5781\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 2.7182,\tval_loss: 2.4893\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 2.5951,\tval_loss: 2.3948\n",
      "6:\t[0s / 0s],\t\ttrain_loss: 2.4830,\tval_loss: 2.2898\n",
      "7:\t[0s / 0s],\t\ttrain_loss: 2.3424,\tval_loss: 2.1898\n",
      "8:\t[0s / 0s],\t\ttrain_loss: 2.2193,\tval_loss: 2.0819\n",
      "9:\t[0s / 0s],\t\ttrain_loss: 2.0996,\tval_loss: 1.9694\n",
      "10:\t[0s / 0s],\t\ttrain_loss: 1.9376,\tval_loss: 1.8410\n",
      "11:\t[0s / 0s],\t\ttrain_loss: 1.8507,\tval_loss: 1.7356\n",
      "12:\t[0s / 0s],\t\ttrain_loss: 1.7816,\tval_loss: 1.6492\n",
      "13:\t[0s / 0s],\t\ttrain_loss: 1.6743,\tval_loss: 1.5671\n",
      "14:\t[0s / 0s],\t\ttrain_loss: 1.6069,\tval_loss: 1.5124\n",
      "15:\t[0s / 0s],\t\ttrain_loss: 1.5324,\tval_loss: 1.4853\n",
      "16:\t[0s / 0s],\t\ttrain_loss: 1.4910,\tval_loss: 1.4638\n",
      "17:\t[0s / 0s],\t\ttrain_loss: 1.4455,\tval_loss: 1.4528\n",
      "18:\t[0s / 0s],\t\ttrain_loss: 1.4347,\tval_loss: 1.4614\n",
      "19:\t[0s / 0s],\t\ttrain_loss: 1.4127,\tval_loss: 1.4495\n",
      "20:\t[0s / 0s],\t\ttrain_loss: 1.4135,\tval_loss: 1.4362\n",
      "21:\t[0s / 0s],\t\ttrain_loss: 1.3899,\tval_loss: 1.4356\n",
      "22:\t[0s / 0s],\t\ttrain_loss: 1.3686,\tval_loss: 1.4441\n",
      "23:\t[0s / 0s],\t\ttrain_loss: 1.3658,\tval_loss: 1.4431\n",
      "24:\t[0s / 0s],\t\ttrain_loss: 1.3552,\tval_loss: 1.4501\n",
      "25:\t[0s / 0s],\t\ttrain_loss: 1.3338,\tval_loss: 1.4639\n",
      "26:\t[0s / 0s],\t\ttrain_loss: 1.3438,\tval_loss: 1.4579\n",
      "27:\t[0s / 0s],\t\ttrain_loss: 1.3183,\tval_loss: 1.4565\n",
      "28:\t[0s / 0s],\t\ttrain_loss: 1.3237,\tval_loss: 1.4621\n",
      "29:\t[0s / 0s],\t\ttrain_loss: 1.3097,\tval_loss: 1.4657\n",
      "30:\t[0s / 0s],\t\ttrain_loss: 1.3438,\tval_loss: 1.4638\n",
      "31:\t[0s / 0s],\t\ttrain_loss: 1.3155,\tval_loss: 1.4643\n",
      "shapes : (381, 381, 381, 381)\n",
      "PyCox: cindex 0.5449389693473057 , ibs 0.17933940355272943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:10<00:00, 963.96it/s]\n",
      "100%|██████████| 100/100 [00:02<00:00, 41.69it/s]\n",
      "100%|██████████| 10000/10000 [00:10<00:00, 983.32it/s]\n",
      "100%|██████████| 100/100 [00:02<00:00, 36.36it/s]\n",
      "100%|██████████| 10000/10000 [00:10<00:00, 979.96it/s]\n",
      "100%|██████████| 100/100 [00:02<00:00, 33.56it/s]\n",
      "100%|██████████| 10000/10000 [00:10<00:00, 972.31it/s]\n",
      "100%|██████████| 100/100 [00:03<00:00, 31.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shapes : (381, 381, 381, 381)\n",
      "Deep Survival Machines: cindex 0.0 , ibs nan\n",
      "shapes : (381, 381, 381, 381)\n",
      "Cox Proportional Hazards: cindex 0.607519918364143 , ibs 0.17498796741261524\n",
      "shapes : (381, 381, 381, 381)\n",
      "Weibull Accelerated Failure Time: cindex 0.6110129910907022 , ibs 0.17663067235510943\n",
      "shapes : (381, 381, 381, 381)\n",
      "Random Survival Forest: cindex 0.6314612033439303 , ibs 0.17305955357321945\n",
      "CPU times: total: 2min 3s\n",
      "Wall time: 1min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#-----------------------------------------------------------------------------------------------\n",
    "# instantiate - PyCox\n",
    "pyc = PYC(configs = configs, train_data = x_train, test_data = x_test, val_data = x_val, num_durations = 10)\n",
    "\n",
    "# fit\n",
    "pyc.fit()\n",
    "\n",
    "# eval\n",
    "pyc_cindex , pyc_ibs = pyc.eval()\n",
    "        \n",
    "print(f'PyCox: cindex {pyc_cindex} , ibs {pyc_ibs}')\n",
    "#-----------------------------------------------------------------------------------------------\n",
    "# instantiate - Deep Survival Machines\n",
    "dsm = DSM(configs = configs, train_data = x_train, test_data = x_test, val_data = x_val, num_durations = 10)\n",
    "\n",
    "# fit\n",
    "dsm.fit()\n",
    "\n",
    "# eval\n",
    "dsm_cindex , dsm_ibs = dsm.eval()\n",
    "       \n",
    "print(f'Deep Survival Machines: cindex {dsm_cindex} , ibs {dsm_ibs}')\n",
    "\n",
    "# -----------------------------------------------------------------------------------------------\n",
    "# instantiate - CPH\n",
    "cph = CPH(configs = configs, train_data = x_train, test_data = x_test, val_data = x_val)\n",
    "\n",
    "# fit\n",
    "cph.fit()\n",
    "# eval\n",
    "cph_cindex , cph_ibs = cph.eval(fitter_is_rsf = False)\n",
    "        \n",
    "print(f'Cox Proportional Hazards: cindex {cph_cindex} , ibs {cph_ibs}')\n",
    "\n",
    "#-----------------------------------------------------------------------------------------------\n",
    "# instantiate - AFT\n",
    "aft = AFT(configs = configs, train_data = x_train, test_data = x_test, val_data = x_val)\n",
    "\n",
    "# fit\n",
    "aft.fit()\n",
    "# eval\n",
    "aft_cindex , aft_ibs = aft.eval(fitter_is_rsf = False)\n",
    "        \n",
    "print(f'Weibull Accelerated Failure Time: cindex {aft_cindex} , ibs {aft_ibs}')\n",
    "\n",
    "#-----------------------------------------------------------------------------------------------\n",
    "# instantiate - RSF\n",
    "rsf = RSF(configs = configs, train_data = x_train, test_data = x_test, val_data = x_val)\n",
    "\n",
    "# fit\n",
    "rsf.fit()\n",
    "# eval\n",
    "rsf_cindex , rsf_ibs = rsf.eval(fitter_is_rsf = True)\n",
    "\n",
    "\n",
    "print(f'Random Survival Forest: cindex {rsf_cindex} , ibs {rsf_ibs}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
