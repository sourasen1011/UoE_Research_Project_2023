{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "sys.path.append('../nn_survival_analysis')\n",
    "from nn_survival_analysis.general_utils import *\n",
    "from nn_survival_analysis.model_utils import *\n",
    "from nn_survival_analysis.losses import *\n",
    "from nn_survival_analysis.models import *\n",
    "from nn_survival_analysis.other_nn_models import *\n",
    "from nn_survival_analysis.time_invariant_surv import *\n",
    "from nn_survival_analysis.time_variant_surv import *\n",
    "from nn_survival_analysis.traditional_models import *\n",
    "import scipy\n",
    "from pycox.datasets import metabric\n",
    "from sklearn_pandas import DataFrameMapper \n",
    "\n",
    "# define sigmoid function - will be handy later\n",
    "sigmoid = lambda z : 1 / (1 + np.exp(-z))\n",
    "\n",
    "config_file_path = '../nn_survival_analysis/config.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_splitter(df , test_size = 0.2 , val_size = 0.25 , duration_col = 'futime' , event_col = 'death'):\n",
    "    df_test = df.sample(frac=test_size)\n",
    "    df_train = df.drop(df_test.index)\n",
    "\n",
    "    df_val = df_train.sample(frac=val_size)\n",
    "    df_train = df_train.drop(df_val.index)\n",
    "\n",
    "    return df_train , df_val , df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 'metabric' not locally available. Downloading...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "df = metabric.read_df()\n",
    "df_train , df_test , df_val = train_test_splitter(df)\n",
    "\n",
    "cols_standardize = ['x0', 'x1', 'x2', 'x3', 'x8']\n",
    "cols_leave = ['x4', 'x5', 'x6', 'x7']\n",
    "\n",
    "standardize = [([col], StandardScaler()) for col in cols_standardize]\n",
    "leave = [(col, None) for col in cols_leave]\n",
    "\n",
    "x_mapper = DataFrameMapper(standardize + leave)\n",
    "\n",
    "x_train = x_mapper.fit_transform(df_train).astype('float32')\n",
    "x_val = x_mapper.transform(df_val).astype('float32')\n",
    "x_test = x_mapper.transform(df_test).astype('float32')\n",
    "\n",
    "get_target = lambda df: (df['duration'].values, df['event'].values)\n",
    "y_train_dur , y_train_event = get_target(df_train)\n",
    "y_test_dur , y_test_event = get_target(df_test)\n",
    "y_val_dur , y_val_event = get_target(df_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pd.DataFrame(x_mapper.fit_transform(df_train).astype('float32') , columns = df_train.iloc[: , :-2].columns)\n",
    "x_val = pd.DataFrame(x_mapper.transform(df_val).astype('float32') , columns = df_val.iloc[: , :-2].columns)\n",
    "x_test = pd.DataFrame(x_mapper.transform(df_test).astype('float32') , columns = df_test.iloc[: , :-2].columns)\n",
    "\n",
    "x_train = pd.concat([x_train , df_train[['duration' , 'event']].reset_index().drop('index' , axis = 1)] , axis = 1)\n",
    "x_test = pd.concat([x_test , df_test[['duration' , 'event']].reset_index().drop('index' , axis = 1)] , axis = 1)\n",
    "x_val = pd.concat([x_val , df_val[['duration' , 'event']].reset_index().drop('index' , axis = 1)] , axis = 1)\n",
    "\n",
    "x_train.rename(columns = {'duration':'time_to_event' , 'event': 'death'}, inplace = True)\n",
    "x_test.rename(columns = {'duration':'time_to_event' , 'event': 'death'}, inplace = True)\n",
    "x_val.rename(columns = {'duration':'time_to_event' , 'event': 'death'}, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training cluster 0\n",
      "Epoch 50: Training Loss: 0.0230443, Val Loss: 0.0212367\n",
      "Epoch 100: Training Loss: 0.0138489, Val Loss: 0.0092648\n",
      "Epoch 150: Training Loss: 0.0160065, Val Loss: 0.0028864\n",
      "Epoch 200: Training Loss: 0.0128226, Val Loss: 0.0023874\n",
      "Epoch 250: Training Loss: 0.0011836, Val Loss: 0.0033392\n",
      "Epoch 300: Training Loss: 0.0131717, Val Loss: 0.0142880\n",
      "Epoch 350: Training Loss: -0.0037746, Val Loss: -0.0052630\n",
      "Epoch 400: Training Loss: -0.0079549, Val Loss: -0.0073843\n",
      "shapes : (381, 381, 381, 381)\n",
      "0.621729578589974 0.4333007458885405\n",
      "CPU times: total: 2min\n",
      "Wall time: 29 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Get configs\n",
    "with open(config_file_path, \"r\") as file:\n",
    "        configs = json.load(file)\n",
    "        \n",
    "#-----------------------------------------------------------------------------------------------\n",
    "# instantiate - Time Invariant Survival\n",
    "tis = Time_Invariant_Survival(\n",
    "        configs = configs, \n",
    "        train_data = x_train,\n",
    "        test_data = x_test, \n",
    "        val_data = x_val\n",
    ")\n",
    "\n",
    "# fit\n",
    "tis.fit(verbose = True)\n",
    "mean_ , up_ , low_ , y_test_dur , y_test_event = tis.predict() # Visualize -> tis.visualize(mean_ , up_ , low_ , _from = 40 , _to = 50 )\n",
    "tis_cindex , tis_ibs = tis.evaluation(mean_ , y_test_dur , y_test_event, plot = False)\n",
    "print(tis_cindex , tis_ibs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Other Fitters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\t[0s / 0s],\t\ttrain_loss: 3.1690,\tval_loss: 3.0904\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 2.9098,\tval_loss: 2.8373\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 2.8725,\tval_loss: 2.6685\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 2.7517,\tval_loss: 2.5517\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 2.6576,\tval_loss: 2.4476\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 2.5985,\tval_loss: 2.3644\n",
      "6:\t[0s / 0s],\t\ttrain_loss: 2.4759,\tval_loss: 2.2753\n",
      "7:\t[0s / 0s],\t\ttrain_loss: 2.3749,\tval_loss: 2.1635\n",
      "8:\t[0s / 0s],\t\ttrain_loss: 2.2515,\tval_loss: 2.0344\n",
      "9:\t[0s / 0s],\t\ttrain_loss: 2.1028,\tval_loss: 1.9076\n",
      "10:\t[0s / 0s],\t\ttrain_loss: 2.0265,\tval_loss: 1.7955\n",
      "11:\t[0s / 0s],\t\ttrain_loss: 1.8949,\tval_loss: 1.7005\n",
      "12:\t[0s / 0s],\t\ttrain_loss: 1.7600,\tval_loss: 1.6043\n",
      "13:\t[0s / 1s],\t\ttrain_loss: 1.7098,\tval_loss: 1.5283\n",
      "14:\t[0s / 1s],\t\ttrain_loss: 1.6254,\tval_loss: 1.4700\n",
      "15:\t[0s / 1s],\t\ttrain_loss: 1.5257,\tval_loss: 1.4418\n",
      "16:\t[0s / 1s],\t\ttrain_loss: 1.5549,\tval_loss: 1.4226\n",
      "17:\t[0s / 1s],\t\ttrain_loss: 1.5107,\tval_loss: 1.4113\n",
      "18:\t[0s / 1s],\t\ttrain_loss: 1.4427,\tval_loss: 1.3921\n",
      "19:\t[0s / 1s],\t\ttrain_loss: 1.4353,\tval_loss: 1.3852\n",
      "20:\t[0s / 1s],\t\ttrain_loss: 1.4482,\tval_loss: 1.3834\n",
      "21:\t[0s / 1s],\t\ttrain_loss: 1.4245,\tval_loss: 1.3820\n",
      "22:\t[0s / 1s],\t\ttrain_loss: 1.4274,\tval_loss: 1.3785\n",
      "23:\t[0s / 1s],\t\ttrain_loss: 1.4182,\tval_loss: 1.3781\n",
      "24:\t[0s / 1s],\t\ttrain_loss: 1.3916,\tval_loss: 1.3817\n",
      "25:\t[0s / 1s],\t\ttrain_loss: 1.4353,\tval_loss: 1.3879\n",
      "26:\t[0s / 1s],\t\ttrain_loss: 1.3998,\tval_loss: 1.3977\n",
      "27:\t[0s / 2s],\t\ttrain_loss: 1.4164,\tval_loss: 1.3996\n",
      "28:\t[0s / 2s],\t\ttrain_loss: 1.3766,\tval_loss: 1.3922\n",
      "29:\t[0s / 2s],\t\ttrain_loss: 1.3854,\tval_loss: 1.3847\n",
      "30:\t[0s / 2s],\t\ttrain_loss: 1.3426,\tval_loss: 1.3833\n",
      "31:\t[0s / 2s],\t\ttrain_loss: 1.3631,\tval_loss: 1.3885\n",
      "32:\t[0s / 2s],\t\ttrain_loss: 1.3391,\tval_loss: 1.3908\n",
      "33:\t[0s / 2s],\t\ttrain_loss: 1.3596,\tval_loss: 1.3864\n",
      "shapes : (381, 381, 381, 381)\n",
      "PyCox: cindex 0.5535289769662585 , ibs 0.1705603208555581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 610/10000 [00:02<00:36, 255.94it/s]\n",
      " 14%|█▍        | 14/100 [00:02<00:16,  5.14it/s]\n",
      "  6%|▌         | 610/10000 [00:02<00:37, 248.00it/s]\n",
      " 16%|█▌        | 16/100 [00:03<00:16,  5.01it/s]\n",
      "  6%|▌         | 610/10000 [00:02<00:34, 273.96it/s]\n",
      "  8%|▊         | 8/100 [00:02<00:23,  3.97it/s]\n",
      "  6%|▌         | 610/10000 [00:02<00:41, 226.43it/s]\n",
      " 18%|█▊        | 18/100 [00:03<00:17,  4.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shapes : (381, 381, 381, 381)\n",
      "Deep Survival Machines: cindex 0.6403699782248237 , ibs 0.34104402019157726\n",
      "shapes : (381, 381, 381, 381)\n",
      "Cox Proportional Hazards: cindex 0.6597878418602793 , ibs 0.17181585111251882\n",
      "shapes : (381, 381, 381, 381)\n",
      "Weibull Accelerated Failure Time: cindex 0.6624048584613541 , ibs 0.1705047102713802\n",
      "shapes : (381, 381, 381, 381)\n",
      "Random Survival Forest: cindex 0.6482410052540104 , ibs 0.1706838736598975\n",
      "CPU times: total: 1min 21s\n",
      "Wall time: 46.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#-----------------------------------------------------------------------------------------------\n",
    "# instantiate - PyCox\n",
    "pyc = PYC(configs = configs, train_data = x_train, test_data = x_test, val_data = x_val, num_durations = 10)\n",
    "\n",
    "# fit\n",
    "pyc.fit()\n",
    "\n",
    "# eval\n",
    "pyc_cindex , pyc_ibs = pyc.eval()\n",
    "        \n",
    "print(f'PyCox: cindex {pyc_cindex} , ibs {pyc_ibs}')\n",
    "#-----------------------------------------------------------------------------------------------\n",
    "# instantiate - Deep Survival Machines\n",
    "dsm = DSM(configs = configs, train_data = x_train, test_data = x_test, val_data = x_val, num_durations = 10)\n",
    "\n",
    "# fit\n",
    "dsm.fit()\n",
    "\n",
    "# eval\n",
    "dsm_cindex , dsm_ibs = dsm.eval()\n",
    "       \n",
    "print(f'Deep Survival Machines: cindex {dsm_cindex} , ibs {dsm_ibs}')\n",
    "\n",
    "# -----------------------------------------------------------------------------------------------\n",
    "# instantiate - CPH\n",
    "cph = CPH(configs = configs, train_data = x_train, test_data = x_test, val_data = x_val)\n",
    "\n",
    "# fit\n",
    "cph.fit()\n",
    "# eval\n",
    "cph_cindex , cph_ibs = cph.eval(fitter_is_rsf = False)\n",
    "        \n",
    "print(f'Cox Proportional Hazards: cindex {cph_cindex} , ibs {cph_ibs}')\n",
    "\n",
    "#-----------------------------------------------------------------------------------------------\n",
    "# instantiate - AFT\n",
    "aft = AFT(configs = configs, train_data = x_train, test_data = x_test, val_data = x_val)\n",
    "\n",
    "# fit\n",
    "aft.fit()\n",
    "# eval\n",
    "aft_cindex , aft_ibs = aft.eval(fitter_is_rsf = False)\n",
    "        \n",
    "print(f'Weibull Accelerated Failure Time: cindex {aft_cindex} , ibs {aft_ibs}')\n",
    "\n",
    "#-----------------------------------------------------------------------------------------------\n",
    "# instantiate - RSF\n",
    "rsf = RSF(configs = configs, train_data = x_train, test_data = x_test, val_data = x_val)\n",
    "\n",
    "# fit\n",
    "rsf.fit()\n",
    "# eval\n",
    "rsf_cindex , rsf_ibs = rsf.eval(fitter_is_rsf = True)\n",
    "\n",
    "\n",
    "print(f'Random Survival Forest: cindex {rsf_cindex} , ibs {rsf_ibs}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
