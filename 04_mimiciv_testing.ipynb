{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # imports\n",
    "# import psycopg2\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import json\n",
    "# from sqlalchemy import create_engine\n",
    "# import matplotlib.pyplot as plt\n",
    "# from scipy import interpolate\n",
    "\n",
    "# resolution = 100 # can head to config file\n",
    "\n",
    "# # access creds\n",
    "# with open('psql_key.json') as file:\n",
    "#     creds = json.load(file)\n",
    "\n",
    "# # Create an SQLAlchemy engine with the PostgreSQL database URI\n",
    "# engine = create_engine(f\"postgresql+psycopg2://{creds['user']}:{creds['password']}@{creds['host']}:{creds['port']}/{creds['database']}\")\n",
    "\n",
    "# # these diag codes were taken from table mimiciv_hosp.d_icd_diagnoses\n",
    "# hf_codes = \"('39891','40200','40201','40210','40211','40290','40291','40400','40401','40402','40403','40410','40411','40412','40413','40490','40491','40492','40493','4280','4281','42820','42821','42822','42823','42830','42831','42832','42833','42840','42841','42842','42843','4289','E8726','E8745','I0981','I110','I119','I130','I131','I1310','I1311','I132','I50','I501','I502','I5020','I5021','I5022','I5023','I503','I5030','I5031','I5032','I5033','I504','I5040','I5041','I5042','I5043','I508','I5081','I50810','I50811','I50812','I50813','I50814','I5082','I5083','I5084','I5089','I509','I9713','I97130','I97131','T8622','T8632','Y625')\"\n",
    "\n",
    "# # get all admissions related to HF codes\n",
    "# query = f'''\n",
    "# select a.* from (select * from mimiciv_hosp.diagnoses_icd where icd_code in {hf_codes}) d\n",
    "# inner join (select * from mimiciv_hosp.admissions) a\n",
    "# on a.hadm_id = d.hadm_id\n",
    "# '''\n",
    "# all_hf_pats = pd.read_sql_query(query , engine)\n",
    "\n",
    "# # QC\n",
    "# print(all_hf_pats['subject_id'].nunique())\n",
    "# # all_hf_pats.head(2)\n",
    "\n",
    "# # Count of times patients have been admitted with a HF diagnosis\n",
    "\n",
    "# hist_df = all_hf_pats.groupby('subject_id').agg({'admittime':'nunique'}).reset_index().groupby('admittime').agg({'subject_id':'nunique'}).reset_index()\n",
    "# hist_df.columns = ['num_admits' , 'patients']\n",
    "# hist_df['cumulative_patients'] = hist_df['patients'].cumsum()\n",
    "# # hist_df.head()\n",
    "\n",
    "# # Retain all patients\n",
    "# # Add num of ICU admits / num of admissions as covariates\n",
    "# # Time of survival -> from last ICU admission to deathtime / OR first ICU admission?\n",
    "# # Uncensored patients (those that experienced the event, i.e. died)\n",
    "# # Find latest ICU admission\n",
    "# tos_hf = all_hf_pats.groupby('subject_id').agg({'admittime':'min' , 'deathtime':'max' , 'dischtime':'max'})\n",
    "# event_pats = tos_hf[tos_hf['deathtime'].notnull()].copy()\n",
    "# event_pats['time_to_event'] = event_pats['deathtime'] - event_pats['admittime']\n",
    "# event_pats['time_to_event'] = event_pats['time_to_event'] / np.timedelta64(1, 'D') # convert to hours\n",
    "# event_pats['Uncensored'] = 1\n",
    "# # event_pats.head(3)\n",
    "\n",
    "# # who are the censored patients?\n",
    "# non_event_pats = tos_hf[tos_hf['deathtime'].isnull()].copy()# For censored patients, their last follow-up was essentially their discharge time\n",
    "# non_event_pats['time_to_event'] = non_event_pats['dischtime'] - non_event_pats['admittime']\n",
    "# non_event_pats['time_to_event'] = non_event_pats['time_to_event'] / np.timedelta64(1, 'D') # convert to hours\n",
    "# # non_event_pats['time_to_event'] = non_event_pats['time_to_event'] + 365 # is this necessary?\n",
    "# non_event_pats['Uncensored'] = 0\n",
    "# # non_event_pats.head(3)\n",
    "\n",
    "# pats = pd.concat([non_event_pats[['time_to_event' , 'Uncensored']] , event_pats[['time_to_event' , 'Uncensored']]] , axis = 0)\n",
    "# pats.reset_index(inplace = True)\n",
    "# pats.sort_values('subject_id' , inplace = True)\n",
    "# # pats.head()\n",
    "\n",
    "# # Try to get vital signs\n",
    "\n",
    "# query = f'''\n",
    "# select * from mimiciv_ed.vitalsign\n",
    "# '''\n",
    "# vitalsign = pd.read_sql_query(query , engine)\n",
    "# # pats_vitalsign = vitalsign.merge(pats['subject_id'] , on = 'subject_id' , how = 'inner')\n",
    "# # pats_vitalsign_list = pats_vitalsign.subject_id.unique()\n",
    "# # print(f'unique patients: {pats_vitalsign.subject_id.nunique()}')\n",
    "\n",
    "# # # Get survival\n",
    "# # pats_survival = pats.merge(vitalsign['subject_id'] , on = 'subject_id' , how = 'inner')\n",
    "# # print(f'unique patients: {pats_survival.subject_id.nunique()}')\n",
    "# # pats_survival.tail()\n",
    "\n",
    "# pats_all_metrics = vitalsign.merge(pats , on = 'subject_id' , how = 'inner')\n",
    "# print(f'unique patients: {pats_all_metrics.subject_id.nunique()}')\n",
    "# # pats_all_metrics.tail()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
